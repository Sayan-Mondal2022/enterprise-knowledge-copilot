{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661842c6",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "1. Load the **PDFs or Markdown** files in Order\n",
    "2. Extract the **data/content** from the PDF\n",
    "3. Then perform chunking - *Because the context window for the LLMs are small*\n",
    "4. Then pass it to the **Embedding Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e8ac08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sayan\\OneDrive\\Desktop\\internship-project\\enterprise-knowledge-copilot\\langchain-service\\.langchain-venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. Loading of the PDFs\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e85ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILE_PATH = \"C:/Users/sayan/OneDrive/Desktop/internship-project/enterprise-knowledge-copilot/data\"\n",
    "\n",
    "# Function to load PDF files from a specified directory\n",
    "def load_pdf_file(file_path=FILE_PATH):\n",
    "    if not os.path.isdir(file_path):\n",
    "        print(f\"Error: The provided path '{file_path}' is not a directory.\")\n",
    "        return []\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        file_path,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "        recursive=True,\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load Markdown files from a specified directory\n",
    "def load_markdown_file(file_path=FILE_PATH):\n",
    "    if not os.path.isdir(file_path):\n",
    "        print(f\"Error: The provided path '{file_path}' is not a directory.\")\n",
    "        return []\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        file_path,\n",
    "        glob=\"**/*.md\",           \n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b72cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to clean markdown text\n",
    "def clean_markdown(md_text: str) -> str:\n",
    "    # 1. Remove YAML front matter\n",
    "    md_text = re.sub(r\"^---.*?---\", \"\", md_text, flags=re.DOTALL)\n",
    "\n",
    "    # 2. Convert markdown → HTML\n",
    "    html = markdown.markdown(md_text)\n",
    "\n",
    "    # 3. Parse HTML\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 4. Remove unwanted tags\n",
    "    for tag in soup([\"script\", \"style\", \"iframe\", \"img\", \"table\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # 5. Get text\n",
    "    text = soup.get_text(separator=\"\\n\")\n",
    "\n",
    "    # 6. Remove markdown links but keep text\n",
    "    text = re.sub(r\"\\[(.*?)\\]\\(.*?\\)\", r\"\\1\", text)\n",
    "\n",
    "    # 7. Normalize whitespace\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "459975d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters documents to only include page_content and source metadata.\n",
    "def filter_to_minimal_docs(docs):\n",
    "    minimal_docs = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        full_path = doc.metadata['source']\n",
    "        file_name = os.path.basename(full_path)\n",
    "\n",
    "        minimal_doc = Document(\n",
    "            page_content=clean_markdown(doc.page_content),\n",
    "            metadata={\n",
    "                \"source\": file_name\n",
    "            }\n",
    "        )\n",
    "        minimal_docs.append(minimal_doc)\n",
    "\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b0c5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(minimal_docs)\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62cb2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Markdown files\n",
    "docs = load_markdown_file()\n",
    "\n",
    "# Filtering to only include page_content and source metadata.\n",
    "minimal_docs = filter_to_minimal_docs(docs)\n",
    "\n",
    "# Split the minimized documents into text chunks\n",
    "text_chunks = text_split(minimal_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac214c1b",
   "metadata": {},
   "source": [
    "## Performing the Vector Embedding on Text Data:\n",
    "\n",
    "The Embedding Model is **Sentence-Transformers**\n",
    "\n",
    "1. The chunks are processed and converted to vectors\n",
    "2. Then the embedded vectors is then sent to the Endee Vector Database using the Endee API\n",
    "3. Once the Data is stored in the the Vector DB, it is now ready to serve as a Knowledge base for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36ba7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 268.75it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embeddingModel = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fa7d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_index = len(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f32a5",
   "metadata": {},
   "source": [
    "### Storing the vector embeddings for each text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03dc0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorEmbeddings = []\n",
    "\n",
    "for id, chunk in enumerate(text_chunks):\n",
    "    source = chunk.metadata['source']\n",
    "    text = chunk.page_content\n",
    "    embedding = embeddingModel.encode(text).tolist()\n",
    "\n",
    "    data = {\n",
    "        \"id\": id + 1,\n",
    "        \"vector\": embedding,\n",
    "        \"meta\": {\n",
    "            \"source\": source,\n",
    "            \"text\": text\n",
    "        }\n",
    "    }\n",
    "    vectorEmbeddings.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b60763b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorEmbeddings[0][\"vector\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b9d2b",
   "metadata": {},
   "source": [
    "### Setting up for connecting with Endee API powered by Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64c2d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Index name for Endee Vector Database\n",
    "INDEX_NAME = \"enterprise_knowledge_base\"\n",
    "\n",
    "# URL for Endee API service\n",
    "ENDEE_URL = \"http://127.0.0.1:8000\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f22fb",
   "metadata": {},
   "source": [
    "### Creating a Index in Endee Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac1eea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payload for creating an index in Endee Vector DB\n",
    "payload_for_create_index = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"dimension\": len(vectorEmbeddings[0][\"vector\"]),\n",
    "    \"precision\": \"INT16D\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a9246e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message for index creation: {'index_name': 'enterprise_knowledge_base', 'status': 'index created'}\n"
     ]
    }
   ],
   "source": [
    "response_for_create_index = requests.post(\n",
    "    f\"{ENDEE_URL}/index/create\",\n",
    "    json=payload_for_create_index\n",
    ")\n",
    "print(f\"Message for index creation: {response_for_create_index.json()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a26a2",
   "metadata": {},
   "source": [
    "### Checking for the Existence of the Index in the Endee Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f50c71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index_name': 'enterprise_knowledge_base', 'status': 'index loaded'}\n"
     ]
    }
   ],
   "source": [
    "response_for_get_index = requests.post(\n",
    "    f\"{ENDEE_URL}/index/get\",\n",
    "    json={\n",
    "        \"index_name\": INDEX_NAME\n",
    "    })\n",
    "print(response_for_get_index.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e8770f",
   "metadata": {},
   "source": [
    "### Inserting the Embedded Vectors into Endee Vector DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "785c62ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_to_insert_multiple_data = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"embedded_vectors\": vectorEmbeddings\n",
    "}\n",
    "\n",
    "payload_to_insert_single_data = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"embedded_vectors\": [vectorEmbeddings[0]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f8db8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 413, 'status': 'vectors upserted'}\n"
     ]
    }
   ],
   "source": [
    "response_for_multiple_insert = requests.post(\n",
    "    f\"{ENDEE_URL}/index/upsert\",\n",
    "    json=payload_to_insert_multiple_data\n",
    ")\n",
    "\n",
    "# response_for_single_insert = requests.post(\n",
    "#     f\"{ENDEE_URL}/index/upsert\",\n",
    "#     json=payload_to_insert_single_data\n",
    "# )\n",
    "\n",
    "print(response_for_multiple_insert.json())\n",
    "# print(response_for_single_insert.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30dd914",
   "metadata": {},
   "source": [
    "### Retrieving the Top K most relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How to become a developer at Gitlab?\"\n",
    "embedding_for_query = embeddingModel.encode(query).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8057467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"vector\": embedding_for_query,\n",
    "    \"top_k\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a2d90789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends a query to the Endee API\n",
    "response = requests.post(\n",
    "    f\"{ENDEE_URL}/index/query\",\n",
    "    json=payload\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7fd268",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9d16f",
   "metadata": {},
   "source": [
    "### Build complete RAG Pipeline:\n",
    "\n",
    "1. Using GROQ Cloud for it's Free APIs and Fast response\n",
    "2. Using Langchain as a warapper\n",
    "\n",
    "### How  does this work:\n",
    "\n",
    "1. `retriever`: returns `List[Document]` for a query (Find relevant information)\n",
    "2. `prompt`: a prompt template with `{context}` and `{input}` (Frame the question for the AI)\n",
    "3. `chatModel`: an LLM runnable (Generate the answer)\n",
    "4. `RunnablePassthrough`: Carry the user’s question forward unchanged\n",
    "5. `StrOutputParser`: Clean the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b93d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853cf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "142727ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Answer in three to five sentences for general questions.\n",
    "and if the answer needs to be more elaborate, provide more details like provide step by step instructions only when needed.\n",
    "Use the context given below for your reference and keep the answer concise and to the point.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "If a user ask whether they can upload a Document, respond with \"Yes, you can upload a PDF Document only.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac4594bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98f5daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endee_retriever(query: str):\n",
    "    embedding_for_query = embeddingModel.encode(query).tolist()\n",
    "\n",
    "    payload = {\n",
    "        \"index_name\": INDEX_NAME,\n",
    "        \"vector\": embedding_for_query,\n",
    "        \"top_k\": 5\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{ENDEE_URL}/index/query\",\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    docs = []\n",
    "    for d in data.get(\"matches\", []):\n",
    "        text = d.get(\"text\", \"\")\n",
    "\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=text,\n",
    "                metadata={\n",
    "                    \"similarity\": d.get(\"similarity\"),\n",
    "                    \"source\": d.get(\"source\")\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return docs\n",
    "\n",
    "retriever = RunnableLambda(endee_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e4271d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93560e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rag pipeline:\n",
    "\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | (lambda docs: \"\\n\\n\".join(d.page_content for d in docs)),\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c815af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To apply for a job at GitLab, follow these steps: \\n1. Visit the GitLab website and navigate to the \"Jobs\" or \"Careers\" page. \\n2. Browse through the available job openings and select the one that matches your skills and interests. \\n3. Click on the job title to view the job description and requirements. \\n4. If you\\'re a good fit, click the \"Apply\" button and fill out the application form, uploading your resume and cover letter as required. \\n5. Submit your application and wait for the GitLab team to review it.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample test:\n",
    "rag_chain.invoke(\"How can I apply for a job at Gitlab?, tell me in steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c30277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: The company information is not provided in our context, but I can tell you that we support document uploads. Yes, you can upload a PDF Document only. If you have any specific questions about the company, I'd be happy to try and help.\n",
      "Assistant: Yes, you can upload a PDF Document only.\n",
      "Exiting the chat. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Testing the RAG pipeline with user input in a loop\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting the chat. Goodbye!\")\n",
    "        break\n",
    "\n",
    "    response = rag_chain.invoke(user_input)\n",
    "    print(f\"Assistant: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
