{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "950cba0a",
   "metadata": {},
   "source": [
    "## Testing the **Single Index** vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661842c6",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "1. Load the **PDFs or Markdown** files in Order\n",
    "2. Extract the **data/content** from the PDF\n",
    "3. Then perform chunking - *Because the context window for the LLMs are small*\n",
    "4. Then pass it to the **Embedding Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23e8ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Loading of the PDFs\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader, TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5b6f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "DATA_FILE_PATH = os.path.join(parent_dir, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e85ed93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load PDF files from a specified directory\n",
    "def load_pdf_file(file_path=DATA_FILE_PATH):\n",
    "    if not os.path.isdir(file_path):\n",
    "        print(f\"Error: The provided path '{file_path}' is not a directory.\")\n",
    "        return []\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        file_path,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "        recursive=True,\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Function to load Markdown files from a specified directory\n",
    "# This function doesn't extract all the required data.\n",
    "def load_markdown_file(file_path=DATA_FILE_PATH):\n",
    "    if not os.path.isdir(file_path):\n",
    "        print(f\"Error: The provided path '{file_path}' is not a directory.\")\n",
    "        return []\n",
    "\n",
    "    loader = DirectoryLoader(\n",
    "        file_path,\n",
    "        glob=\"**/*.md\",           \n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={\"encoding\": \"utf-8\"}\n",
    "    )\n",
    "\n",
    "    docs = loader.load()\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2318f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import frontmatter\n",
    "from pathlib import Path\n",
    "\n",
    "# This will be the Function to load MARKDOWN FILES\n",
    "def load_md_with_metadata(path):\n",
    "    docs = []\n",
    "\n",
    "    for file in Path(path).rglob(\"*.md\"):\n",
    "        post = frontmatter.load(file)\n",
    "\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=post.content,\n",
    "                metadata={\n",
    "                    \"title\": post.get(\"title\"),\n",
    "                    \"description\": post.get(\"description\"),\n",
    "                    \"source\": str(file)\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "84b72cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import markdown\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Function to clean markdown text\n",
    "def clean_markdown(md_text: str) -> str:\n",
    "    # 1. Remove YAML front matter\n",
    "    md_text = re.sub(r\"^---.*?---\", \"\", md_text, flags=re.DOTALL)\n",
    "\n",
    "    # 2. Convert markdown â†’ HTML\n",
    "    html = markdown.markdown(md_text)\n",
    "\n",
    "    # 3. Parse HTML\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 4. Remove unwanted tags\n",
    "    for tag in soup([\"script\", \"style\", \"iframe\", \"img\", \"table\"]):\n",
    "        tag.decompose()\n",
    "\n",
    "    # 5. Get text\n",
    "    text = soup.get_text(separator=\" \")\n",
    "\n",
    "    # 6. Remove markdown links but keep text\n",
    "    text = re.sub(r\"\\[(.*?)\\]\\(.*?\\)\", r\"\\1\", text)\n",
    "\n",
    "    # 7. Normalize whitespace\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "459975d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filters documents to only include page_content and source metadata.\n",
    "def filter_to_minimal_docs(docs):\n",
    "    minimal_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        full_path = doc.metadata.get(\"source\", \"\")\n",
    "        file_name = os.path.basename(full_path)\n",
    "\n",
    "        minimal_doc = Document(\n",
    "            page_content = clean_markdown(doc.page_content),\n",
    "            metadata={\n",
    "                \"title\": doc.metadata.get(\"title\"),\n",
    "                \"description\": doc.metadata.get(\"description\"),\n",
    "                \"source\": file_name\n",
    "            }\n",
    "        )\n",
    "\n",
    "        minimal_docs.append(minimal_doc)\n",
    "\n",
    "    return minimal_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b0c5ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into smaller chunks\n",
    "def text_split(minimal_docs):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(minimal_docs)\n",
    "    return split_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "62cb2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Markdown files\n",
    "docs = load_md_with_metadata(DATA_FILE_PATH)\n",
    "\n",
    "# Filtering to only include page_content and source metadata.\n",
    "minimal_docs = filter_to_minimal_docs(docs)\n",
    "\n",
    "# Split the minimized documents into text chunks\n",
    "text_chunks = text_split(minimal_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac214c1b",
   "metadata": {},
   "source": [
    "## Performing the Vector Embedding on Text Data:\n",
    "\n",
    "The Embedding Model is **Sentence-Transformers**\n",
    "\n",
    "1. The chunks are processed and converted to vectors\n",
    "2. Then the embedded vectors is then sent to the Endee Vector Database using the Endee API\n",
    "3. Once the Data is stored in the the Vector DB, it is now ready to serve as a Knowledge base for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b36ba7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 176.28it/s, Materializing param=pooler.dense.weight]                             \n",
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embeddingModel = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73f32a5",
   "metadata": {},
   "source": [
    "### Storing the vector embeddings for each text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "03dc0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = 1\n",
    "vectorEmbeddings = []\n",
    "\n",
    "for id, chunk in enumerate(text_chunks):\n",
    "    source = chunk.metadata.get('source', \"\")\n",
    "    title = chunk.metadata.get(\"title\", \"\")\n",
    "    description = chunk.metadata.get(\"description\", \"\")\n",
    "    text = chunk.page_content\n",
    "    embedding = embeddingModel.encode(text).tolist()\n",
    "\n",
    "    data = {\n",
    "        \"id\": id + start_idx,\n",
    "        \"vector\": embedding,\n",
    "        \"meta\": {\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"source\": source,\n",
    "            \"text\": text\n",
    "        }\n",
    "    }\n",
    "    vectorEmbeddings.append(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073b9d2b",
   "metadata": {},
   "source": [
    "### Setting up for connecting with Endee API powered by Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "64c2d1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import ConnectionError, Timeout, HTTPError\n",
    "\n",
    "# Index name for Endee Vector Database\n",
    "INDEX_NAME = \"enterprise_knowledge_base2\"\n",
    "\n",
    "# URL for Endee API service\n",
    "ENDEE_URL = \"http://127.0.0.1:8000\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5f22fb",
   "metadata": {},
   "source": [
    "### Creating a Index in Endee Vector Database\n",
    "\n",
    "Using only the Dense Vectors (***Vector Embeddings***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac1eea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payload for creating an index in Endee Vector DB\n",
    "payload = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"dimension\": embeddingModel.get_sentence_embedding_dimension(),\n",
    "    \"precision\": \"INT16D\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a9246e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message for index creation: {'index_name': 'enterprise_knowledge_base2', 'status': 'index created'}\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    response = requests.post(\n",
    "        f\"{ENDEE_URL}/index/create\",\n",
    "        json=payload\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(f\"Message for index creation: {response.json()}\")\n",
    "\n",
    "except ConnectionError:\n",
    "    print(\"Backend service is not reachable (is it running?)\")\n",
    "    \n",
    "except Timeout:\n",
    "    print(\"Request timed out\")\n",
    "    \n",
    "except HTTPError as e:\n",
    "    try:\n",
    "        err = e.response.json()\n",
    "        print(\"Error message:\", err.get(\"error\"))\n",
    "    except ValueError:\n",
    "        print(\"Raw error:\", e.response.text)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a26a2",
   "metadata": {},
   "source": [
    "### Checking for the Existence of the Index in the Endee Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f50c71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'index_name': 'enterprise_knowledge_base2', 'status': 'index loaded'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{ENDEE_URL}/index/get\",\n",
    "        json={\n",
    "            \"index_name\": INDEX_NAME\n",
    "        })\n",
    "    \n",
    "    response.raise_for_status()\n",
    "    print(response.json())\n",
    "    \n",
    "except ConnectionError:\n",
    "    print(\"Backend service is not reachable (is it running?)\")\n",
    "    \n",
    "except Timeout:\n",
    "    print(\"Request timed out\")\n",
    "    \n",
    "except HTTPError as e:\n",
    "    try:\n",
    "        err = e.response.json()\n",
    "        print(\"Error message:\", err.get(\"error\"))\n",
    "    except ValueError:\n",
    "        print(\"Raw error:\", e.response.text)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e8770f",
   "metadata": {},
   "source": [
    "### Inserting the Embedded Vectors into Endee Vector DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785c62ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error message: list indices must be integers or slices, not str\n"
     ]
    }
   ],
   "source": [
    "# Single query/chunk\n",
    "payload = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"embedded_vectors\": [vectors]\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(\n",
    "        f\"{ENDEE_URL}/index/upsert\",\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    response.raise_for_status()\n",
    "    print(response.json())\n",
    "    \n",
    "except ConnectionError:\n",
    "    print(\"Backend service is not reachable (is it running?)\")\n",
    "    \n",
    "except Timeout:\n",
    "    print(\"Request timed out\")\n",
    "    \n",
    "except HTTPError as e:\n",
    "    try:\n",
    "        err = e.response.json()\n",
    "        print(\"Error message:\", err.get(\"error\"))\n",
    "    except ValueError:\n",
    "        print(\"Raw error:\", e.response.text)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b94cc98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing list slicing because, insertion limit is 1000 vectors, and I am keeping 950 vectors per upsert\n",
    "slices = []\n",
    "\n",
    "end = len(vectorEmbeddings) // 950\n",
    "prev = 0\n",
    "for i in range(1, end + 1):\n",
    "    slices.append((prev, 950 * i + 1))\n",
    "    prev = 950 * i + 1\n",
    "slices.append((prev, len(vectorEmbeddings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3f8db8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function to UPSERT the VECTORS into DB\n",
    "def upsertVectors(vectors):\n",
    "    payload = {\n",
    "            \"index_name\": INDEX_NAME,\n",
    "            \"embedded_vectors\": vectors\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            f\"{ENDEE_URL}/index/upsert\",\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        print(response.json())\n",
    "        return True\n",
    "\n",
    "    except ConnectionError:\n",
    "        print(\"Backend service is not reachable (is it running?)\")\n",
    "\n",
    "    except Timeout:\n",
    "        print(\"Request timed out\")\n",
    "\n",
    "    except HTTPError as e:\n",
    "        try:\n",
    "            err = e.response.json()\n",
    "            print(\"Error message:\", err.get(\"error\"))\n",
    "        except ValueError:\n",
    "            print(\"Raw error:\", e.response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a3bf408f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'count': 951, 'status': 'vectors upserted'}\n",
      "{'count': 950, 'status': 'vectors upserted'}\n",
      "{'count': 950, 'status': 'vectors upserted'}\n",
      "{'count': 950, 'status': 'vectors upserted'}\n",
      "{'count': 950, 'status': 'vectors upserted'}\n",
      "{'count': 741, 'status': 'vectors upserted'}\n"
     ]
    }
   ],
   "source": [
    "for start, end in slices:\n",
    "    vectors = vectorEmbeddings[start:end]\n",
    "    \n",
    "    if not upsertVectors(vectors):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30dd914",
   "metadata": {},
   "source": [
    "### Retrieving the Top K most relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460756c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'description': 'Learn more about working with Manav Khurana, CPMO at GitLab.', 'distance': 0.7510538846254349, 'id': '3176', 'similarity': 0.24894611537456512, 'text': 'Manav Khurana is the current Chief Product and Marketing Officer \\n About Me \\n Manav Kurana is a business-minded technical person. Two things drive my work practice: \\n \\n \\n Solving customer problems â€“ more of them and doing so in the best way. \\n \\n \\n Optimizing for business results in what we do.', 'title': 'Manav Khurana - Chief Product and Marketing Officer - README'}, {'description': 'Learn more about working with Manav Khurana, CPMO at GitLab.', 'distance': 0.759822741150856, 'id': '3178', 'similarity': 0.24017725884914398, 'text': 'Manav Kurana was born and raised in New Delhi, India. Manav Kurana came to the U.S. to study electrical and computer engineering in New York and then moved to San Francisco for whatâ€™s now been a 25-year career in tech. My wife, whom Manav Kurana met in college, is a psychologist and keeps me accountable to our value system ðŸ™‚. We have a 12-year-old son, who is pure joy to be around and inspires us with his curiosity. We cherish our time together at home, with our community, and in our travels.', 'title': 'Manav Khurana - Chief Product and Marketing Officer - README'}]\n"
     ]
    }
   ],
   "source": [
    "# Sample RETRIEVAL of data relevant to queries.\n",
    "query = \"Who is Sayan Mondal\"\n",
    "embedding_for_query = embeddingModel.encode(query).tolist()\n",
    "\n",
    "payload = {\n",
    "    \"index_name\": INDEX_NAME,\n",
    "    \"vector\": embedding_for_query,\n",
    "    \"top_k\": 20\n",
    "}\n",
    "\n",
    "# Sends a query to the Endee API\n",
    "response = requests.post(\n",
    "    f\"{ENDEE_URL}/index/query\",\n",
    "    json=payload\n",
    ")\n",
    "\n",
    "data = response.json()\n",
    "print(data[\"results\"][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9d16f",
   "metadata": {},
   "source": [
    "### Build complete RAG Pipeline:\n",
    "\n",
    "1. Using GROQ Cloud for it's Free APIs and Fast response\n",
    "2. Using Langchain as a warapper\n",
    "\n",
    "### How  does this work:\n",
    "\n",
    "1. `retriever`: returns `List[Document]` for a query (Find relevant information)\n",
    "2. `prompt`: a prompt template with `{context}` and `{input}` (Frame the question for the AI)\n",
    "3. `chatModel`: an LLM runnable (Generate the answer)\n",
    "4. `RunnablePassthrough`: Carry the userâ€™s question forward unchanged\n",
    "5. `StrOutputParser`: Clean the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3b93d487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the environment variables from the .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4594bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853cf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model_name=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "98f5daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is wrapper for retrieving the data\n",
    "def endee_retriever(query: str):\n",
    "    embedding_for_query = embeddingModel.encode(query).tolist()\n",
    "\n",
    "    payload = {\n",
    "        \"index_name\": INDEX_NAME,\n",
    "        \"vector\": embedding_for_query,\n",
    "        \"top_k\": 20\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        f\"{ENDEE_URL}/index/query\",\n",
    "        json=payload\n",
    "    )\n",
    "\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    docs = []\n",
    "    for d in data.get(\"results\", []):\n",
    "        text = d.get(\"text\", \"\")\n",
    "\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=text,\n",
    "                metadata={\n",
    "                    \"similarity\": d.get(\"similarity\"),\n",
    "                    \"source\": d.get(\"source\"),\n",
    "                    \"title\": d.get(\"title\"),\n",
    "                    \"description\": d.get(\"description\")\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return docs\n",
    "\n",
    "retriever = RunnableLambda(endee_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "142727ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a professional and a helpful virtual assistant for a Company named GitLab.\n",
    "Your name is 'GitLab Copilot' and your job is to answer to all the queries made by the employees of this company to make their work easier.\n",
    "Answer in three to five sentences for general questions.\n",
    "and if the answer needs to be more elaborated, provide more details like step by step instructions only when needed or asked specifically by the user.\n",
    "Use the context given below for your reference and keep the answer concise and to the point.\n",
    "Respond in detail only when the user specifies it.\n",
    "And always perform a Double check before giving the final response to the user.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "If a user ask whether they can upload a Document, respond with \"Yes, you can upload a PDF Document only.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93560e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the Prompt\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Rag pipeline:\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": retriever | (lambda docs: \"\\n\\n\".join(d.page_content for d in docs)),\n",
    "        \"input\": RunnablePassthrough()\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cf8ce6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prepare for an interview, here's a step-by-step guide:\n",
      "\n",
      "1. **Review the Job Description**: Study the job description and requirements to understand the skills and qualifications needed for the position.\n",
      "2. **Research the Company**: Learn about the company's mission, values, products, and services to demonstrate your interest and knowledge.\n",
      "3. **Update Your Resume and Online Profiles**: Ensure your resume and online profiles (e.g., LinkedIn) are up-to-date and highlight your relevant skills and experiences.\n",
      "4. **Prepare Common Interview Questions**: Familiarize yourself with common interview questions, such as \"Why do you want to work for this company?\" or \"What are your strengths and weaknesses?\"\n",
      "5. **Practice Your Responses**: Prepare thoughtful responses to these questions, using the STAR method ( Situation, Task, Action, Result) to structure your answers.\n",
      "6. **Develop Questions to Ask the Interviewer**: Prepare a list of questions to ask the interviewer, such as \"What are the biggest challenges facing the team?\" or \"Can you tell me more about the company culture?\"\n",
      "7. **Review Industry Trends and News**: Stay current with industry trends and news to demonstrate your knowledge and interest in the field.\n",
      "8. **Prepare Examples of Your Work**: Gather examples of your work, such as projects or accomplishments, to showcase your skills and experiences.\n",
      "9. **Practice Your Interview Skills**: Use online resources or practice with a friend or mentor to improve your interview skills, such as body language, tone, and pace.\n",
      "10. **Get Ready Logistically**: Ensure you have all the necessary documents, such as your resume and references, and plan your transportation and attire for the interview.\n",
      "\n",
      "Additionally, consider the following tips:\n",
      "- Be ready to talk about your skills, experiences, and achievements.\n",
      "- Show enthusiasm and interest in the company and position.\n",
      "- Use positive body language and tone.\n",
      "- Follow up with a thank-you note or email after the interview.\n",
      "\n",
      "By following these steps, you'll be well-prepared for your interview and increase your chances of success.\n"
     ]
    }
   ],
   "source": [
    "# Sample test:\n",
    "print(rag_chain.invoke(\"If I want to prepare for an Interview, what all should I need to learn, can you guide me in this. Tell me step by step in detail\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77883555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CES stands for Candidate Experience Specialist. Here are the key points about CES and its use in Team Interviews:\n",
      "\n",
      "* CES is responsible for scheduling technical interviews with candidates.\n",
      "* CES utilizes tools like ModernLoop and GitLab Service Desk to track and manage interview requests.\n",
      "* Key responsibilities of CES in Team Interviews include:\n",
      "  * Scheduling interviews with team members\n",
      "  * Sending interview confirmations to candidates\n",
      "  * Coordinating with interviewers and candidates to find suitable interview times\n",
      "  * Ensuring a smooth and efficient interview process\n",
      "* CES follows a specific process for scheduling interviews, including:\n",
      "  * Receiving availability requests from candidates\n",
      "  * Sending interview invites to interviewers\n",
      "  * Confirming interview details with candidates\n",
      "* CES also handles non-standard requests and escalations, and maintains communication with candidates and interviewers throughout the interview process.\n"
     ]
    }
   ],
   "source": [
    "print(rag_chain.invoke(\"what is the use of CES in Team Interviews and also tell what is CES?, give me in points\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121a106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is no information about Sayan Mondal in the provided context. If you have any other questions or need assistance with something else, feel free to ask.\n"
     ]
    }
   ],
   "source": [
    "# Answers only when relevant data is retrieved\n",
    "print(rag_chain.invoke(\"Who is Sayan Mondal\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "35c30277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "Assistant: Hello, I'm GitLab Copilot. How can I assist you today?\n",
      "\n",
      "User: WHo are you\n",
      "Assistant: I'm GitLab Copilot, a professional and helpful virtual assistant for GitLab. I'm here to answer your queries and make your work easier.\n",
      "\n",
      "User: What can you do for me?\n",
      "Assistant: I'm GitLab Copilot, your virtual assistant. I can help answer your queries, provide guidance, and make your work easier. If you have any questions or need assistance with anything related to GitLab, feel free to ask, and I'll do my best to help. Whether it's about our values, workflows, or technical aspects, I'm here to support you. What's on your mind?\n",
      "\n",
      "User: How can I get a job in this company\n",
      "Assistant: To apply for a job at GitLab, you can visit the internal job openings page. Additionally, you can join the #newvacancy channel in Slack to stay updated on new openings. If you have any questions about the hiring process, you can create an issue in the hiring process repo or reach out to a Recruiter directly. You can also check the hiring page for more information on the company's hiring process and requirements.\n",
      "\n",
      "User: What are the stages in Hiring an employee, give me in points\n",
      "Assistant: Here are the stages in hiring an employee at GitLab:\n",
      "\n",
      "* Application\n",
      "* Interview process (including behavioral, situational, and technical interviews)\n",
      "* Talent Assessment\n",
      "* Calibration and evaluation\n",
      "* Offer stage\n",
      "* Hire-in process (including onboarding and transition to the new role)\n",
      "\n",
      "User: What are the Job roles available in this compnay\n",
      "Assistant: The company, GitLab, has various job roles available, including Backend Engineer, Site Reliability Engineer, Database Reliability Engineer, Engineering Manager, Solutions Architect, Customer Success Manager, Product Manager, Director of Product, VP of Product, and Support Engineer, among others. Additionally, there are roles such as Infrastructure Operator, Systems Engineer, and DevOps Engineer. These roles are spread across different departments, including Infrastructure, Product, and Support.\n",
      "\n",
      "User: what is Gitlab?\n",
      "Assistant: GitLab is a software company that enables people to contribute to and co-create the software that powers our world. It's a DevSecOps platform that helps teams collaborate, develop, and deliver software. GitLab's mission is to help people increase their lifetime earnings through access to opportunities and its platform.\n",
      "\n",
      "User: How is work life in this company\n",
      "Assistant: At GitLab, the work-life balance is valued and encouraged. As a company, GitLab prioritizes giving team members the freedom to own their projects and initiatives, and trusts them to manage their time effectively. This approach allows team members to have a better balance between their work and personal life. The company culture is also open, transparent, and inclusive, which fosters a positive and supportive work environment. Overall, GitLab strives to create a work environment where team members can thrive and be their best selves.\n",
      "\n",
      "User: Is there Remote Job oppertunity\n",
      "Assistant: Yes, GitLab offers remote job opportunities. As an all-remote company, we hire great people regardless of where they live, with team members across more than 65 countries. You can explore our current job openings and apply to join our team.\n",
      "\n",
      "User: exit\n",
      "\n",
      "Exiting the chat. Goodbye!!!\n"
     ]
    }
   ],
   "source": [
    "# Testing the RAG pipeline with user input in a loop\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    print(f\"User: {user_input}\")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"\\nExiting the chat. Goodbye!!!\")\n",
    "        break\n",
    "\n",
    "    response = rag_chain.invoke(user_input)\n",
    "    print(f\"Assistant: {response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86b4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".langchain-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
